{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#python -m pip install opencv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scaleFactor – Parameter specifying how much the image size is reduced at each image scale.\n",
    "\n",
    "\n",
    "- min_neighbors-Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "\n",
    "\n",
    "- minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "\n",
    "\n",
    "- maxSize – Maximum possible object size. Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faceDetect=cv2.CascadeClassifier('xml/frontal_face.xml')\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "while True:\n",
    "    ret,img = cam.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceDetect.detectMultiScale(gray,scaleFactor=1.3,minNeighbors=3)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Face\",img)\n",
    "    if (cv2.waitKey(10)== ord('q')):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#scaleFactor – Parameter specifying how much the image size is reduced at each image scale.\n",
    "#min_neighbors-Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "#minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "#maxSize – Maximum possible object size. Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Build Our Dataset</h2>\n",
    "<h4 align=\"center\">\n",
    "Detect $\\rightarrow$ Cut $\\rightarrow$ Normalize $\\rightarrow$ Resize $\\rightarrow$ Save</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def detect_face(frame):\n",
    "    detector = cv2.CascadeClassifier(\"xml/frontal_face.xml\")\n",
    "\n",
    "    \n",
    "    #faces = detector.detectMultiScale(frame,scaleFactor=1.3,minNeighbors=5)\n",
    "    scale_factor = 1.2\n",
    "    min_neighbors =5\n",
    "    min_size = (30,30)\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "\n",
    "    faces = detector.detectMultiScale(frame,scaleFactor=scale_factor,\n",
    "                                     minNeighbors=min_neighbors,\n",
    "                                     minSize=min_size,\n",
    "                                     flags=flags)\n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "      \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        #w_rm = int(0.2 * w / 2)\n",
    "        faces.append(image[y: y + h, x : x + w ])\n",
    "         \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize faces by increasing pixel intensity(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        is_color = len(image.shape) == 3 \n",
    "        if is_color:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### cv.INTER_AREA for shrinking & cv.INTER_CUBIC for zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_CUBIC)\n",
    "        else:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_AREA)\n",
    "        image_resize.append(img_size)\n",
    "        \n",
    "    return image_resize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_faces(frame, faces_coord):\n",
    "    faces = cut_faces(frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    \n",
    "    faces = resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_show(image,title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        #w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x , y), (x + w , y + h), (0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "#cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "folder = \"people/\"+input('Person:').lower()\n",
    "\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "    flag_start_capturing = False\n",
    "    sample=1\n",
    "    #cam = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        \n",
    "        \n",
    "        \n",
    "        faces_coord = detect_face(frame)\n",
    "\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(frame,faces_coord)\n",
    "            #faces = normalize_intensity(faces)\n",
    "            cv2.imwrite(folder + '/' + str(sample)+'.jpg',faces[0])\n",
    "            plot_show(faces[0],\"Image saved:\"+str(sample))\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "        draw_rectangle(frame,faces_coord)\n",
    "        cv2.imshow('Face',frame)\n",
    "        keypress=cv2.waitKey(1)\n",
    "        \n",
    "        if keypress == ord('c'):\n",
    "            \n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            else:\n",
    "                flag_start_capturing = False\n",
    "                sample = 0\n",
    "        \n",
    "        if flag_start_capturing == True:\n",
    "            sample += 1\n",
    "        if sample >15:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    ".else:\n",
    "    print (\"This name already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### datasets for other class\n",
    "\n",
    "basepath = 'C:\\\\Users\\\\Vineet\\\\scikit_learn_data\\\\lfw_home\\\\lfw_funneled\\\\'\n",
    "#C:\\Users\\Vineet\\scikit_learn_data\\lfw_home\n",
    "images = os.listdir(basepath) \n",
    "print (len(images))\n",
    "data = images[:210]\n",
    "\n",
    "for i,folder in enumerate(data,start=1):\n",
    "    \n",
    "    files=os.listdir(basepath+'\\\\'+folder)\n",
    "    for k,img in enumerate(files,start=1):\n",
    "        if img.endswith('.jpg'):\n",
    "            #print img\n",
    "            frame=cv2.imread(basepath+'\\\\'+folder+'\\\\'+img,0)\n",
    "        #print frame\n",
    "       \n",
    "            faces_coord = detect_face(frame)\n",
    "            if len(faces_coord):\n",
    "                faces = cut_faces(frame, faces_coord)\n",
    "                #print faces\n",
    "                faces = normalize_intensity(faces)\n",
    "                faces = resize(faces)\n",
    "                cv2.imwrite('people/unknown/' + str(i)+'.jpg',faces[0])\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "    #people = [person for person in os.listdir(\"Male_female/\")]\n",
    "    people = [person for person in os.listdir(\"people/\")]\n",
    "    #people = [person for person in os.listdir(\"people/\")]\n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"people/\" + person):\n",
    "            if image.endswith('.jpg'):\n",
    "                images.append(cv2.imread(\"people/\" + person + '/' + image, 0))\n",
    "                labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels, labels_dic = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(images))\n",
    "print (labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=X_train.reshape(len(X_train),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA()\n",
    "pca1.fit(train)\n",
    "plt.plot(np.cumsum(pca1.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=.99)\n",
    "new_train=pca1.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C':[.0001,.001,.01,.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_svc = GridSearchCV(SVC(kernel='linear',probability=True),param_grid=param_grid,cv=kf,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc.fit(new_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc1 = gs_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'svc_face.pkl'\n",
    "f=open(filename, 'wb')\n",
    "pickle.dump(svc1,f)\n",
    " \n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'svc_face.pkl'\n",
    "svc1 = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(1)\n",
    "font=cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.namedWindow(\"opencv_face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    \n",
    "    faces_coord = detect_face(frame) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord)\n",
    "        #faces = normalize_intensity(faces)\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            \n",
    "            \n",
    "            #cv2.imwrite('trainingData/female/picture_BGR5.jpg',face)\n",
    "            test = pca1.transform(face.reshape(1,-1))    \n",
    "            #print test\n",
    "            #transform = test.reshape(1,-1)\n",
    "            #print transform\n",
    "            prob=svc1.predict_proba(test)\n",
    "            confidence = svc1.decision_function(test)\n",
    "            print (confidence)\n",
    "            print (prob)\n",
    "           \n",
    "            \n",
    "            \n",
    "            pred = svc1.predict(test)\n",
    "            print (pred,pred[0])\n",
    "           \n",
    "            name=labels_dic[pred[0]].capitalize()\n",
    "            print (name)\n",
    "            \n",
    "            #pred = labels_dic[pred[0]].capitalize()\n",
    "            #threshold = .50\n",
    "            \n",
    "            if prob[0][1]>.75:\n",
    "                \n",
    "                cv2.putText(frame, 'vineet',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "            elif prob[0][0]>.80:\n",
    "                cv2.putText(frame,'unknown',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "                \n",
    "                \n",
    "            #cv2.putText(frame,name,(x,y-10),font,2,(0,0,255),2,cv2.LINE_AA)\n",
    "            \n",
    "               \n",
    "           #cv2.putText(frame,'Unknown',(x,y-10),font,2,(0,0,255),2,cv2.LINE_AA)\n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        \n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2,\n",
    "                cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"opencv_face\", frame) # live feed in external\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
